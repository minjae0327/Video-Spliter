{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbcde3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:26: SyntaxWarning: invalid escape sequence '\\o'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\o'\n",
      "C:\\Users\\minja\\AppData\\Local\\Temp\\ipykernel_12112\\2605895500.py:26: SyntaxWarning: invalid escape sequence '\\o'\n",
      "  root_dir = \"dataset\\output_frames\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def load_images(root_dir):\n",
    "    image_list = []\n",
    "    \n",
    "    for folder_name in sorted(os.listdir(root_dir)):\n",
    "        folder_path = os.path.join(root_dir, folder_name)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "        \n",
    "        label = folder_name.replace('_', '/')\n",
    "        \n",
    "        image_paths = glob(os.path.join(folder_path, '*.*'))\n",
    "        image_paths = image_paths[:50]\n",
    "        \n",
    "        for img_path in image_paths:\n",
    "            image_list.append({\n",
    "                \"img_path\":img_path,\n",
    "                \"label\":label\n",
    "            })\n",
    "            \n",
    "    return image_list\n",
    "\n",
    "\n",
    "root_dir = \"dataset\\output_frames\"\n",
    "image_label_list = load_images(root_dir)\n",
    "\n",
    "print(len(image_label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba8a0164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"pooler_act\": \"tanh\",\n",
      "  \"pooler_output_size\": 768,\n",
      "  \"qkv_bias\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "# 1. 모델 및 프로세서 준비\n",
    "trocr_processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-printed\")\n",
    "trocr_model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-printed\").to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def predict_trocr(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    pixel_values = trocr_processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "    pixel_values = pixel_values.to(trocr_model.device)\n",
    "    generated_ids = trocr_model.generate(pixel_values)\n",
    "    pred = trocr_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return pred.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca806b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7464cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e9fb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(torch.__version__)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(torch.backends)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.backends)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de7fa5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch.backends'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measyocr\u001b[39;00m\n\u001b[32m      2\u001b[39m easyocr_reader = easyocr.Reader([\u001b[33m'\u001b[39m\u001b[33men\u001b[39m\u001b[33m'\u001b[39m], gpu=torch.cuda.is_available())\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_easyocr\u001b[39m(image_path):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minja\\anaconda3\\envs\\easyOCR\\Lib\\site-packages\\easyocr\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01measyocr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Reader\n\u001b[32m      3\u001b[39m __version__ = \u001b[33m'\u001b[39m\u001b[33m1.7.2\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minja\\anaconda3\\envs\\easyOCR\\Lib\\site-packages\\easyocr\\easyocr.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrecognition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_recognizer, get_text\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m group_text_box, get_image_list, calculate_md5, get_paragraph,\\\n\u001b[32m      5\u001b[39m                    download_and_unzip, printProgressBar, diff, reformat_input,\\\n\u001b[32m      6\u001b[39m                    make_rotated_img_list, set_result_with_confidence,\\\n\u001b[32m      7\u001b[39m                    reformat_input_batched, merge_to_free\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\minja\\anaconda3\\envs\\easyOCR\\Lib\\site-packages\\easyocr\\recognition.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcudnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcudnn\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch.backends'"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "easyocr_reader = easyocr.Reader(['en'], gpu=torch.cuda.is_available())\n",
    "\n",
    "\n",
    "def predict_easyocr(image_path):\n",
    "    results = easyocr_reader.readtext(image_path, detail=0)\n",
    "    if results:\n",
    "        return results[0].strip()\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "505b28da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import editdistance\n",
    "\n",
    "def cer(s1, s2):\n",
    "    # 문자단위 Levenshtein 거리\n",
    "    return editdistance.eval(s1, s2) / max(len(s2), 1)\n",
    "\n",
    "def wer(ref, hyp):\n",
    "    # 단어단위 Levenshtein 거리\n",
    "    ref_words = ref.split()\n",
    "    hyp_words = hyp.split()\n",
    "    import editdistance\n",
    "    return editdistance.eval(hyp_words, ref_words) / max(len(ref_words), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8562f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TROCR CER: 0.0000 / WER: 0.0000\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for item in image_label_list:\n",
    "    img_path = item[\"img_path\"]\n",
    "    gt_label = item[\"label\"]\n",
    "\n",
    "    # 추론\n",
    "    pred_trocr = predict_trocr(img_path)\n",
    "\n",
    "    # 평가\n",
    "    cer_t = cer(pred_trocr, gt_label)\n",
    "    wer_t = wer(pred_trocr, gt_label)\n",
    "\n",
    "    all_results.append({\n",
    "        \"img\": img_path,\n",
    "        \"gt\": gt_label,\n",
    "        \"trocr_pred\": pred_trocr,\n",
    "        \"cer_trocr\": cer_t,\n",
    "        \"wer_trocr\": wer_t,\n",
    "    })\n",
    "\n",
    "\n",
    "# 평균 CER/WER 계산\n",
    "trocr_cer = np.mean([r['cer_trocr'] for r in all_results])\n",
    "trocr_wer = np.mean([r['wer_trocr'] for r in all_results])\n",
    "\n",
    "print(f\"TROCR CER: {trocr_cer:.4f} / WER: {trocr_wer:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d38c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "for item in image_label_list:\n",
    "    img_path = item[\"img_path\"]\n",
    "    gt_label = item[\"label\"]\n",
    "\n",
    "    # 추론\n",
    "    pred_easyocr = predict_easyocr(img_path)\n",
    "\n",
    "    # 평가\n",
    "    cer_e = cer(pred_easyocr, gt_label)\n",
    "    wer_e = wer(pred_easyocr, gt_label)\n",
    "\n",
    "    all_results.append({\n",
    "        \"img\": img_path,\n",
    "        \"gt\": gt_label,\n",
    "        \"easyocr_pred\": pred_easyocr,\n",
    "        \"cer_easyocr\": cer_e,\n",
    "        \"wer_easyocr\": wer_e\n",
    "    })\n",
    "\n",
    "easyocr_cer = np.mean([r['cer_easyocr'] for r in all_results])\n",
    "easyocr_wer = np.mean([r['wer_easyocr'] for r in all_results])\n",
    "\n",
    "print(f\"EASYOCR CER: {easyocr_cer:.4f} / WER: {easyocr_wer:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easyOCR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
